{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5c9715-a861-4b13-88f7-3cf7115678e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.27.0.4  87.73 KiB   16      100.0%            75ca6567-5b44-4628-b6f9-11bfe6c14d10  rack1\n",
      "UN  172.27.0.3  87.74 KiB   16      100.0%            15207ec3-aa22-4d39-8551-50d0845662ea  rack1\n",
      "UN  172.27.0.2  113.16 KiB  16      100.0%            491b0306-0dd3-4ecb-9220-b276727eaf94  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca525cc-2995-43af-bfd2-7babd31f9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['p6-db-1', 'p6-db-2', 'p6-db-3'])\n",
    "cass = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d565805-24f2-46cb-a76a-e3839cde0af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fdbc471a3b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"drop keyspace if exists weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb84679-c42c-44dd-a9a4-1d5cb3214c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fdbf024e620>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"create keyspace weather with replication={'class': 'SimpleStrategy', 'replication_factor': 3};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "618330fe-d96e-4d3c-b531-7e65d2d75f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fdbc50e2a10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"use weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0118416-3236-4bbc-bdc1-6562fa5abc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fdbc50e31c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"\"\"\n",
    "create type weather.station_record(\n",
    "    tmin INT,\n",
    "    tmax INT\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d017e1d-b2b5-48a2-9c35-2f0c5ff8ed95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fdbc4719330>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"\"\"\n",
    "create table weather.stations(\n",
    "    id  TEXT,\n",
    "    name TEXT static,\n",
    "    date DATE,\n",
    "    record weather.station_record,\n",
    "    PRIMARY KEY (id, date)\n",
    ") WITH CLUSTERING ORDER BY (date ASC)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ecb160-a454-4ea1-b3ef-e082cd6075f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE weather.stations (\n",
      "    id text,\n",
      "    date date,\n",
      "    name text static,\n",
      "    record station_record,\n",
      "    PRIMARY KEY (id, date)\n",
      ") WITH CLUSTERING ORDER BY (date ASC)\n",
      "    AND additional_write_policy = '99p'\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND cdc = false\n",
      "    AND comment = ''\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND memtable = 'default'\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND extensions = {}\n",
      "    AND gc_grace_seconds = 864000\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 0\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair = 'BLOCKING'\n",
      "    AND speculative_retry = '99p';\n"
     ]
    }
   ],
   "source": [
    "print(cass.execute(\"describe table weather.stations\").one().create_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64154420-0b56-4c77-a0da-6ae1308b081f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9e564370-bccc-44bb-a7c6-8283bcadc888;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 1328ms :: artifacts dl 72ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   0   ||   18  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9e564370-bccc-44bb-a7c6-8283bcadc888\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 18 already retrieved (0kB/30ms)\n",
      "23/11/22 20:53:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"p6\")\n",
    "         .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.0')\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff356370-c3d4-470a-9861-605b91cbaf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290ff8e2-f945-4dba-b4a0-5a13c31c7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "df = spark.read.text(\"ghcnd-stations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619cfeb8-81e9-41b3-be54-1ad6078f28f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604  17.1167  -61.7833   10.1    ST JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647  17.1333  -61.7833   19.2    ST JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196  25.3330   55.5170   34.0    SHARJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194  25.2550   55.3640   10.4    DUBAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217  24.4330   54.6510   26.8    ABU D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123341</th>\n",
       "      <td>ZI000067969 -21.0500   29.3670  861.0    WEST ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123342</th>\n",
       "      <td>ZI000067975 -20.0670   30.8670 1095.0    MASVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123343</th>\n",
       "      <td>ZI000067977 -21.0170   31.5830  430.0    BUFFA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123344</th>\n",
       "      <td>ZI000067983 -20.2000   32.6160 1132.0    CHIPI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123345</th>\n",
       "      <td>ZI000067991 -22.2170   30.0000  457.0    BEITB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123346 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    value\n",
       "0       ACW00011604  17.1167  -61.7833   10.1    ST JO...\n",
       "1       ACW00011647  17.1333  -61.7833   19.2    ST JO...\n",
       "2       AE000041196  25.3330   55.5170   34.0    SHARJ...\n",
       "3       AEM00041194  25.2550   55.3640   10.4    DUBAI...\n",
       "4       AEM00041217  24.4330   54.6510   26.8    ABU D...\n",
       "...                                                   ...\n",
       "123341  ZI000067969 -21.0500   29.3670  861.0    WEST ...\n",
       "123342  ZI000067975 -20.0670   30.8670 1095.0    MASVI...\n",
       "123343  ZI000067977 -21.0170   31.5830  430.0    BUFFA...\n",
       "123344  ZI000067983 -20.2000   32.6160 1132.0    CHIPI...\n",
       "123345  ZI000067991 -22.2170   30.0000  457.0    BEITB...\n",
       "\n",
       "[123346 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e381e5b0-aea8-48b8-a6d0-26031df8e0b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td></td>\n",
       "      <td>ST JOHNS COOLIDGE FLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td></td>\n",
       "      <td>ST JOHNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td></td>\n",
       "      <td>SHARJAH INTER. AIRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td></td>\n",
       "      <td>DUBAI INTL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td></td>\n",
       "      <td>ABU DHABI INTL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123341</th>\n",
       "      <td>ZI000067969</td>\n",
       "      <td></td>\n",
       "      <td>WEST NICHOLSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123342</th>\n",
       "      <td>ZI000067975</td>\n",
       "      <td></td>\n",
       "      <td>MASVINGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123343</th>\n",
       "      <td>ZI000067977</td>\n",
       "      <td></td>\n",
       "      <td>BUFFALO RANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123344</th>\n",
       "      <td>ZI000067983</td>\n",
       "      <td></td>\n",
       "      <td>CHIPINGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123345</th>\n",
       "      <td>ZI000067991</td>\n",
       "      <td></td>\n",
       "      <td>BEITBRIDGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123346 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id state                            name\n",
       "0       ACW00011604        ST JOHNS COOLIDGE FLD         \n",
       "1       ACW00011647        ST JOHNS                      \n",
       "2       AE000041196        SHARJAH INTER. AIRP           \n",
       "3       AEM00041194        DUBAI INTL                    \n",
       "4       AEM00041217        ABU DHABI INTL                \n",
       "...             ...   ...                             ...\n",
       "123341  ZI000067969        WEST NICHOLSON                \n",
       "123342  ZI000067975        MASVINGO                      \n",
       "123343  ZI000067977        BUFFALO RANGE                 \n",
       "123344  ZI000067983        CHIPINGE                      \n",
       "123345  ZI000067991        BEITBRIDGE                    \n",
       "\n",
       "[123346 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "df = df.select(\n",
    "    expr(\"substring(value, 0, 11)\").alias(\"id\"),\n",
    "    expr(\"substring(value, 39, 2)\").alias(\"state\"),\n",
    "    expr(\"substring(value, 42, 30)\").alias(\"name\"),\n",
    ")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5861ae5-1925-425c-8b05-f0c5c7065932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, state: string, name: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.where(df.state == 'WI')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a881e0c6-17a3-4b1a-afc6-d3cb3ab01f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "099f5954-c592-47a3-b274-86ff7acf1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_statement = cass.prepare(\"\"\"\n",
    "INSERT INTO weather.stations (id, name)\n",
    "VALUES (?, ?)\n",
    "\"\"\")\n",
    "\n",
    "for row in data:\n",
    "    cass.execute(insert_statement, (row.id, row.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed1b8496-0da6-4e3f-bd9e-7dae74a2a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE weather.stations (\\n    id text,\\n    date date,\\n    name text static,\\n    record station_record,\\n    PRIMARY KEY (id, date)\\n) WITH CLUSTERING ORDER BY (date ASC)\\n    AND additional_write_policy = '99p'\\n    AND bloom_filter_fp_chance = 0.01\\n    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\\n    AND cdc = false\\n    AND comment = ''\\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\\n    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\\n    AND memtable = 'default'\\n    AND crc_check_chance = 1.0\\n    AND default_time_to_live = 0\\n    AND extensions = {}\\n    AND gc_grace_seconds = 864000\\n    AND max_index_interval = 2048\\n    AND memtable_flush_period_in_ms = 0\\n    AND min_index_interval = 128\\n    AND read_repair = 'BLOCKING'\\n    AND speculative_retry = '99p';\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "count_stations = cass.execute(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM weather.stations\n",
    "\"\"\")\n",
    "cass.execute(\"describe table weather.stations\").one()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ed4751c-6743-4bfc-bca8-30b91eff4b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MADISON DANE CO RGNL AP       '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "stations = cass.execute(\"\"\"\n",
    "SELECT name\n",
    "FROM weather.stations\n",
    "WHERE id = 'USW00014837'\n",
    "\"\"\")\n",
    "stations.one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "901d5751-8b15-4e66-b4d8-0d19d05a8e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9014250178872933741"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "stations = cass.execute(\"\"\"\n",
    "SELECT token(id)\n",
    "FROM weather.stations\n",
    "WHERE id = 'USC00470273'\n",
    "\"\"\")\n",
    "stations.one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17ae21b5-2bf3-4104-aefa-c00825044c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9008888552508841246"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4 @@@@@@@@@@@@@@@@@@@Handle the case where the ring \"wraps around\" \n",
    "stations = cass.execute(\"\"\"\n",
    "SELECT token(id)\n",
    "FROM weather.stations\n",
    "WHERE token(id) > token('USC00470273')\n",
    "\"\"\")\n",
    "stations.one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ac4d5a-e21e-4fe2-8193-a096b428264e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fdba3153250>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = cass.execute(\"\"\"\n",
    "SELECT token(id)\n",
    "FROM weather.stations\n",
    "WHERE id = 'USC00470273'\n",
    "\"\"\")\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "425a36ed-2512-496f-ba03-5a8535bcf4a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_tmax\n",
       "0           None\n",
       "1           None\n",
       "2           None\n",
       "3           None\n",
       "4           None\n",
       "...          ...\n",
       "1308        None\n",
       "1309        None\n",
       "1310        None\n",
       "1311        None\n",
       "1312        None\n",
       "\n",
       "[1313 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cass.execute(\"select record.tmax from weather.stations\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fbf4812-386a-436f-9991-2a83202dad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not\n",
    "# !unzip records.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "141d3482-1c9f-4d94-ba8b-4c83a7c7f2ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>element</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00014898</td>\n",
       "      <td>20220101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00014898</td>\n",
       "      <td>20220102</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00014898</td>\n",
       "      <td>20220103</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00014898</td>\n",
       "      <td>20220104</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00014898</td>\n",
       "      <td>20220105</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19629</th>\n",
       "      <td>USR0000WDDG</td>\n",
       "      <td>20221227</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>-114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630</th>\n",
       "      <td>USR0000WDDG</td>\n",
       "      <td>20221228</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19631</th>\n",
       "      <td>USR0000WDDG</td>\n",
       "      <td>20221229</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19632</th>\n",
       "      <td>USR0000WDDG</td>\n",
       "      <td>20221230</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>-31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19633</th>\n",
       "      <td>USR0000WDDG</td>\n",
       "      <td>20221231</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19634 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           station      date element  value\n",
       "0      USW00014898  20220101    TMAX  -32.0\n",
       "1      USW00014898  20220102    TMAX  -77.0\n",
       "2      USW00014898  20220103    TMAX  -60.0\n",
       "3      USW00014898  20220104    TMAX    0.0\n",
       "4      USW00014898  20220105    TMAX  -16.0\n",
       "...            ...       ...     ...    ...\n",
       "19629  USR0000WDDG  20221227    TAVG -114.0\n",
       "19630  USR0000WDDG  20221228    TAVG    2.0\n",
       "19631  USR0000WDDG  20221229    TAVG   72.0\n",
       "19632  USR0000WDDG  20221230    TAVG  -31.0\n",
       "19633  USR0000WDDG  20221231    TAVG  -30.0\n",
       "\n",
       "[19634 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"p6\").getOrCreate()\n",
    "record_df = spark.read.parquet('records.parquet')\n",
    "record_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "198600c1-bdd4-4733-9a26-988420340170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(record_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b15a680-d61e-4899-bf64-6bef2358bbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(station='USW00014898', date='20220101', element='TMAX', value=-32.0),\n",
       " Row(station='USW00014898', date='20220102', element='TMAX', value=-77.0),\n",
       " Row(station='USW00014898', date='20220103', element='TMAX', value=-60.0),\n",
       " Row(station='USW00014898', date='20220104', element='TMAX', value=0.0),\n",
       " Row(station='USW00014898', date='20220105', element='TMAX', value=-16.0),\n",
       " Row(station='USW00014898', date='20220106', element='TMAX', value=-71.0),\n",
       " Row(station='USW00014898', date='20220107', element='TMAX', value=-71.0),\n",
       " Row(station='USW00014898', date='20220108', element='TMAX', value=-32.0),\n",
       " Row(station='USW00014898', date='20220109', element='TMAX', value=-27.0),\n",
       " Row(station='USW00014898', date='20220110', element='TMAX', value=-149.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_df.rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd987d93-e478-4145-9b6d-a65d253e91d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(station='USW00014898', date='20220101', element='TMAX', value=-32.0),\n",
       " Row(station='USW00014898', date='20220102', element='TMAX', value=-77.0),\n",
       " Row(station='USW00014898', date='20220103', element='TMAX', value=-60.0),\n",
       " Row(station='USW00014898', date='20220104', element='TMAX', value=0.0),\n",
       " Row(station='USW00014898', date='20220105', element='TMAX', value=-16.0),\n",
       " Row(station='USW00014898', date='20220106', element='TMAX', value=-71.0),\n",
       " Row(station='USW00014898', date='20220107', element='TMAX', value=-71.0),\n",
       " Row(station='USW00014898', date='20220108', element='TMAX', value=-32.0),\n",
       " Row(station='USW00014898', date='20220109', element='TMAX', value=-27.0),\n",
       " Row(station='USW00014898', date='20220110', element='TMAX', value=-149.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df = record_df.rdd.filter(lambda x: \"TMAX\" or \"TMIN\" in x.element)\n",
    "# records_df = record_df.rdd.groupBy((\"station\",\"date\"))       \n",
    "records_df.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65701fbc-2c2d-46af-a13d-3cb55feb0b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "# records_df = record_df.rdd.filter(lambda x: \"TMAX\" or \"TMIN\" in x.element)\n",
    "df_transformed = (record_df\n",
    "                  .filter(record_df.element.isin([\"TMIN\", \"TMAX\"]))\n",
    "                  .groupBy(\"station\", \"date\")\n",
    "                  .pivot(\"element\")\n",
    "                  .agg({'value': 'first'})\n",
    "                  .withColumnRenamed(\"TMAX\", \"tmax\")\n",
    "                  .withColumnRenamed(\"TMIN\", \"tmin\")\n",
    "                  .withColumn(\"date\", to_date(col(\"date\"), \"yyyyMMdd\"))\n",
    "                 )\n",
    "records = df_transformed.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae597634-4a26-46c9-a654-00a9f3bb04f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import grpc\n",
    "import station_pb2_grpc, station_pb2\n",
    "\n",
    "channel = grpc.insecure_channel(\"localhost:5440\")\n",
    "stub = station_pb2_grpc.StationStub(channel)\n",
    "\n",
    "for record in records:\n",
    "    # print(type(record.station),type(record.date), type(record.tmin))\n",
    "    response = stub.RecordTemps(station_pb2.RecordTempsRequest(\n",
    "        station = record.station,\n",
    "        date = str(record.date),\n",
    "        tmin = int(record.tmin),\n",
    "        tmax = int(record.tmax)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7af8f00d-9e31-4bab-8f53-6ebd61f32f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5\n",
    "response = stub.StationMax(station_pb2.StationMaxRequest(station='USW00014837'))\n",
    "response.tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9ed14c6-8fe2-4a58-852c-2e4d5e7fad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"org.apache.spark.sql.cassandra\")\n",
    ".option(\"spark.cassandra.connection.host\", \"p6-db-1,p6-db-2,p6-db-3\")\n",
    ".option(\"keyspace\", \"weather\")\n",
    ".option(\"table\", \"stations\")\n",
    ".load())\n",
    "\n",
    "df.createOrReplaceTempView(\"stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e17f42e0-9c6c-4bc5-a92c-695ef03873cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='stations', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bf83ba1-d792-4715-a36b-f56b42d84c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gas_station': 22.0,\n",
       " 'USW00014898': 102.93698630136986,\n",
       " 'USR0000WDDG': 102.06849315068493,\n",
       " 'USW00014837': 105.62739726027397,\n",
       " 'USW00014839': 89.6986301369863}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q7\n",
    "avg_diff_df = spark.sql( \"\"\"\n",
    "SELECT id, AVG(record.tmax - record.tmin) as avg_diff\n",
    "FROM stations\n",
    "GROUP BY id\n",
    "HAVING avg_diff is not null\n",
    "\"\"\").toPandas()\n",
    "result = {}\n",
    "for i, row in avg_diff_df.iterrows():\n",
    "    result[row['id']] = row['avg_diff']\n",
    "dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b219f805-1b0b-4009-8fb3-ea693b5baeb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.27.0.4  171.72 KiB  16      100.0%            75ca6567-5b44-4628-b6f9-11bfe6c14d10  rack1\n",
      "UN  172.27.0.3  167.53 KiB  16      100.0%            15207ec3-aa22-4d39-8551-50d0845662ea  rack1\n",
      "UN  172.27.0.2  190.6 KiB   16      100.0%            491b0306-0dd3-4ecb-9220-b276727eaf94  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q8\n",
    "!nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0dad861-84f8-44d3-b350-749597389d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q9\n",
    "response = stub.StationMax(station_pb2.StationMaxRequest(\n",
    "    station = \"USW00014837\"\n",
    "))\n",
    "response.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d6a6720-3e77-4033-bc8b-49d93f2490b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q10\n",
    "response = stub.RecordTemps(station_pb2.RecordTempsRequest(\n",
    "    station = \"gas_station\",\n",
    "    date = '2023-11-22',\n",
    "    tmin = 12,\n",
    "    tmax = 34\n",
    "))\n",
    "response.error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
