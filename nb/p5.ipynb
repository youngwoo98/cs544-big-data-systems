{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youngwoo Kim\n",
    "!hdfs dfs -D dfs.replication=1 -cp -f data/*.csv hdfs://nn:9000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328      328      hdfs://nn:9000/action_taken.csv\n",
      "317      317      hdfs://nn:9000/agency.csv\n",
      "521.0 K  521.0 K  hdfs://nn:9000/arid2017_to_lei_xref_csv.csv\n",
      "311.6 K  311.6 K  hdfs://nn:9000/counties.csv\n",
      "237      237      hdfs://nn:9000/denial_reason.csv\n",
      "109      109      hdfs://nn:9000/edit_status.csv\n",
      "180      180      hdfs://nn:9000/ethnicity.csv\n",
      "166.8 M  166.8 M  hdfs://nn:9000/hdma-wi-2021.csv\n",
      "41       41       hdfs://nn:9000/hoepa.csv\n",
      "114      114      hdfs://nn:9000/lien_status.csv\n",
      "65       65       hdfs://nn:9000/loan_purpose.csv\n",
      "79       79       hdfs://nn:9000/loan_type.csv\n",
      "129.6 K  129.6 K  hdfs://nn:9000/msamd.csv\n",
      "122      122      hdfs://nn:9000/owner_occupancy.csv\n",
      "92       92       hdfs://nn:9000/preapproval.csv\n",
      "127      127      hdfs://nn:9000/property_type.csv\n",
      "387      387      hdfs://nn:9000/purchaser_type.csv\n",
      "252      252      hdfs://nn:9000/race.csv\n",
      "144      144      hdfs://nn:9000/sex.csv\n",
      "955      955      hdfs://nn:9000/states.csv\n",
      "2.6 M    2.6 M    hdfs://nn:9000/tracts.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -du -h hdfs://nn:9000/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/06 00:50:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.appName(\"cs544\")\n",
    "         .master(\"spark://boss:7077\")\n",
    "         .config(\"spark.executor.memory\", \"512M\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"hdfs://nn:9000/user/hive/warehouse\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
