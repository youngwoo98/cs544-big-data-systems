{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youngwoo Kim\n",
    "!hdfs dfs -D dfs.replication=1 -cp -f data/*.csv hdfs://nn:9000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328      328      hdfs://nn:9000/action_taken.csv\n",
      "317      317      hdfs://nn:9000/agency.csv\n",
      "521.0 K  521.0 K  hdfs://nn:9000/arid2017_to_lei_xref_csv.csv\n",
      "311.6 K  311.6 K  hdfs://nn:9000/counties.csv\n",
      "237      237      hdfs://nn:9000/denial_reason.csv\n",
      "109      109      hdfs://nn:9000/edit_status.csv\n",
      "180      180      hdfs://nn:9000/ethnicity.csv\n",
      "166.8 M  166.8 M  hdfs://nn:9000/hdma-wi-2021.csv\n",
      "41       41       hdfs://nn:9000/hoepa.csv\n",
      "114      114      hdfs://nn:9000/lien_status.csv\n",
      "65       65       hdfs://nn:9000/loan_purpose.csv\n",
      "79       79       hdfs://nn:9000/loan_type.csv\n",
      "129.6 K  129.6 K  hdfs://nn:9000/msamd.csv\n",
      "122      122      hdfs://nn:9000/owner_occupancy.csv\n",
      "92       92       hdfs://nn:9000/preapproval.csv\n",
      "127      127      hdfs://nn:9000/property_type.csv\n",
      "387      387      hdfs://nn:9000/purchaser_type.csv\n",
      "252      252      hdfs://nn:9000/race.csv\n",
      "144      144      hdfs://nn:9000/sex.csv\n",
      "955      955      hdfs://nn:9000/states.csv\n",
      "2.6 M    2.6 M    hdfs://nn:9000/tracts.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -du -h hdfs://nn:9000/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/07 21:51:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.appName(\"cs544\")\n",
    "         .master(\"spark://boss:7077\")\n",
    "         .config(\"spark.executor.memory\", \"512M\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"hdfs://nn:9000/user/hive/warehouse\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "banks_df = spark.read.options(header=True, inferSchema=True).csv(\"hdfs://nn:9000/arid2017_to_lei_xref_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(banks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(respondent_name='First National Bank', arid_2017='110004', lei_2018='5493003EW6T31TGECO83', lei_2019='5493003EW6T31TGECO83', lei_2020='5493003EW6T31TGECO83'),\n",
       " Row(respondent_name='First Mid Bank & Trust, National Association', arid_2017='110045', lei_2018='549300XOTES5TCS8T794', lei_2019='549300XOTES5TCS8T794', lei_2020='549300XOTES5TCS8T794'),\n",
       " Row(respondent_name='First Hope Bank, A National Banking Association', arid_2017='110118', lei_2018='5493003XLOX5FDT9R120', lei_2019='5493003XLOX5FDT9R120', lei_2020='5493003XLOX5FDT9R120')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banks_df.rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "banks_df.rdd.filter(lambda x:\"first\" in x.respondent_name.lower()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "banks_df.filter(lower(banks_df.respondent_name).like(\"%first%\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "banks_df.write.saveAsTable(\"banks\", mode=\"overwrite\")\n",
    "spark.sql(\"\"\"\n",
    "            SELECT * FROM banks\n",
    "            WHERE LOWER(respondent_name) LIKE '%first%'\n",
    "            \"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
